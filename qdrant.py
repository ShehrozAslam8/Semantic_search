# -*- coding: utf-8 -*-
"""Qdrant

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KbGvj5W1MUteR4lowxvSg1ROPd2qcqNP
"""

pip install sentence-transformers

pip install qdrant-client

from sentence_transformers import SentenceTransformer
from qdrant_client import QdrantClient
from qdrant_client.http.models import PointStruct, VectorParams
import requests
import numpy as np

# Check if Qdrant server is running
try:
    response = requests.get("http://localhost:6333/health")
    response.raise_for_status()
    print("Qdrant server is running and reachable.")
except requests.exceptions.RequestException as e:
    print(f"Error: {e}")
    print("Please ensure that the Qdrant server is running and accessible at http://localhost:6333")
    raise


# Initialize the Sentence-BERT model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Initialize the Qdrant client
qdrant_client = QdrantClient(host="localhost", port=6333)

# Define the collection name
collection_name = "semantic_search"

# Create a new collection with vector configuration
qdrant_client.recreate_collection(
    collection_name=collection_name,
    vectors_config=VectorParams(size=384, distance="Cosine")
)

# Define the corpus
corpus = [
    "The cat sits on the mat.",
    "Dogs are man's best friend.",
    "Artificial intelligence is the future.",
    "I love reading books on machine learning.",
    "The weather is sunny today."
]

# Encode the corpus
corpus_embeddings = model.encode(corpus)

# Create points and add to Qdrant
points = [
    PointStruct(id=str(i), vector=embedding.tolist(), payload={"sentence": sentence})
    for i, (embedding, sentence) in enumerate(zip(corpus_embeddings, corpus))
]

# Upload points to the collection
qdrant_client.upsert(
    collection_name=collection_name,
    points=points
)

# Define the query
query = "Tell me about AI and its future."

# Encode the query
query_embedding = model.encode(query).tolist()

# Perform the search
search_result = qdrant_client.search(
    collection_name=collection_name,
    query_vector=query_embedding,
    top=5  # Number of top results to return
)

# Display the results
print("Query:", query)
print("\nTop 5 most similar sentences in the corpus:")

for hit in search_result:
    print(f"Score: {hit.score:.4f}\t Sentence: {hit.payload['sentence']}")