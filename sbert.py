# -*- coding: utf-8 -*-
"""SBert

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nfYQ5nO9GBKbHKGCBD-QmIgSoECJZjW7
"""

pip install sentence-transformers

from sentence_transformers import SentenceTransformer, util
import numpy as np

# Load the pre-trained SBERT model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Define the corpus and the query
corpus = [
    "The cat sits on the mat.",
    "Dogs are man's best friend.",
    "Artificial intelligence is the future.",
    "I love reading books on machine learning.",
    "The weather is sunny today."
]
query = "Tell me about AI and its future."

# Encode the corpus and query
corpus_embeddings = model.encode(corpus, convert_to_tensor=True)
query_embedding = model.encode(query, convert_to_tensor=True)

# Compute cosine similarity
cosine_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)

# Find the top N most similar sentences
top_k = min(5, len(corpus))
top_results = np.argpartition(-cosine_scores[0], range(top_k))[0:top_k]

# Display results
print("Query:", query)
print("\nTop 5 most similar sentences in the corpus:")
for idx in top_results[0:top_k]:
    print(f"Score: {cosine_scores[0][idx]:.4f}\t Sentence: {corpus[idx]}")